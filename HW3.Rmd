---
title: "HW3"
author: "Zach Steffens"
date: "2025-10-17"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse,ggplot2)
```

Problem 1:
```{r}
#a)
ages = c(13,15,16,16,19,20,20,21,22,22,25,25,25,25,30,33,33,35,35,35,35,36,40,45,46,52,70)
bin_depth = 3
n = length(ages)
bins = split(ages, ceiling(seq_along(ages) / bin_depth))
bin_mean = sapply(bins,mean)
smoothed = unlist(mapply(function(bm, idx) rep(bm, length(bins[[idx]])), bin_mean, seq_along(bins)))

cat("Original ages:\n"); print(ages)
cat("\nBin means:\n"); print(bin_mean)
cat("\nSmoothed ages (by bin mean):\n"); print(smoothed)

#b)
Q1 = quantile(ages, 0.25, type = 7)
Q3 = quantile(ages, 0.75, type = 7)
IQR_val = IQR(ages, type = 7)
lower_fence = Q1 - 1.5 * IQR_val
upper_fence = Q3 + 1.5 * IQR_val
outliers = ages[ages < lower_fence | ages > upper_fence]
cat("\nIQR summary:\n")
cat("Q1 =", Q1, " Q3 =", Q3, " IQR =", IQR_val, "\n")
cat("Lower fence =", lower_fence, " Upper fence =", upper_fence, "\n")
cat("Outliers (if any):\n"); print(outliers)

#c)
x = 35
min_age = min(ages); max_age = max(ages)
minmax_norm = (x - min_age) / (max_age - min_age)
cat("\nMin-max normalization of 35 on [0,1]:", minmax_norm, "\n")

#d)
mu <- mean(ages)
sigma_sample <- sd(ages) # sample standard deviation (n-1)
sigma_pop <- sqrt(mean((ages - mu)^2)) # population sd (divide by n)
z_sample <- (x - mu) / sigma_sample
z_pop <- (x - mu) / sigma_pop
cat("\nMean:", mu, "\n")
cat("Sample SD (R sd):", sigma_sample, "  Population SD:", sigma_pop, "\n")
cat("Z-score (using sample SD):", z_sample, "\n")
cat("Z-score (using population SD):", z_pop, "\n")

#e)
j = ceiling(log10(max(abs(ages))))
decimal_scaled <- x / (10^j)
cat("\nDecimal scaling j =", j, "  Decimal-scaled value of 35:", decimal_scaled, "\n")

```

Problem 2
```{python}
import numpy as np

def foo(a, new_min=0.0, new_max=1.0):
   
    arr = np.asarray(a, dtype=float)
    if arr.ndim != 1:
        raise ValueError("Input must be a one-dim array")

    old_min = np.nanmin(arr)
    old_max = np.nanmax(arr)

    if np.isnan(old_min) or np.isnan(old_max):
        raise ValueError("Input contains only NaNs or is invalid")

    if old_max == old_min:
        return np.full(arr.shape, (new_min + new_max) / 2.0, dtype=float)

    scaled = (arr - old_min) / (old_max - old_min) # now in [0,1]
    mapped = scaled * (new_max - new_min) + new_min
    return mapped
  
ages = [13,15,16,16,19,20,20,21,22,22,25,25,25,25,30,33,33,35,35,35,35,36,40,45,46,52,70]

# map to [0,1]
norm01 = foo(ages, 0.0, 1.0)

# map to [10,20]
norm10_20 = foo(ages, 10.0, 20.0)

norm01
norm10_20
```
Problem 3
```{r}
library(readxl)
df = read_excel("C:\\Users\\zrsm9\\OneDrive\\Documents\\CSC587\\HW3.3 Table.xlsx")

entropy_counts <- function(counts) {
  probs <- counts[counts > 0] / sum(counts)
  -sum(probs * log2(probs))
}

class_counts = tapply(df$count, df$status, sum)
total <- sum(class_counts)
root_entropy <- entropy_counts(class_counts)
cat("Class counts (junior, senior):\n"); print(class_counts)
cat("Total:", total, "\n")
cat("Root entropy (bits):", round(root_entropy, 6), "\n\n")

info_gain <- function(data, attr, target = "status", weight_col = "count") {
  total_count <- sum(data[[weight_col]])
  # entropy before split
  before_counts <- tapply(data[[weight_col]], data[[target]], sum)
  H_before <- entropy_counts(before_counts)
  # groups by attribute value
  groups <- split(data, data[[attr]])
  # weighted entropy after split
  H_after <- 0
  for (g in groups) {
    counts_g <- tapply(g[[weight_col]], g[[target]], sum)
    H_g <- entropy_counts(counts_g)
    H_after <- H_after + (sum(g[[weight_col]]) / total_count) * H_g
  }
  IG <- H_before - H_after
  list(attribute = attr, H_before = H_before, H_after = H_after, IG = IG)
}

attrs <- c("department","age","salary")
igs <- lapply(attrs, function(a) info_gain(df, a))
igs_df <- do.call(rbind, lapply(igs, function(x) data.frame(attr = x$attribute,
                                                            H_before = x$H_before,
                                                            H_after = x$H_after,
                                                            IG = x$IG)))
igs_df$H_before <- round(igs_df$H_before, 6)
igs_df$H_after  <- round(igs_df$H_after, 6)
igs_df$IG       <- round(igs_df$IG, 6)
print(igs_df)
cat("\nBest root attribute by IG:", igs_df$attr[which.max(igs_df$IG)], "\n\n")

salary_node_value <- "46K_50K"
node_data <- subset(df, salary == salary_node_value)

node_class_counts <- tapply(node_data$count, node_data$status, sum)
node_total <- sum(node_data$count)
node_entropy <- entropy_counts(node_class_counts)
cat("Salary node:", salary_node_value, "\n")
cat("Counts (junior, senior):\n"); print(node_class_counts)
cat("Node total:", node_total, "\n")
cat("Node entropy (bits):", round(node_entropy, 6), "\n\n")

remaining_attrs <- setdiff(attrs, "salary")
igs_node <- lapply(remaining_attrs, function(a) info_gain(node_data, a))
igs_node_df <- do.call(rbind, lapply(igs_node, function(x) data.frame(attr = x$attribute,
                                                                      H_before = x$H_before,
                                                                      H_after = x$H_after,
                                                                      IG = x$IG)))
igs_node_df$H_before <- round(igs_node_df$H_before, 6)
igs_node_df$H_after  <- round(igs_node_df$H_after, 6)
igs_node_df$IG       <- round(igs_node_df$IG, 6)
print(igs_node_df)
cat("\nBest attribute to split salary =", salary_node_value, ":", igs_node_df$attr[which.max(igs_node_df$IG)], "\n")
```
Problem 4
```{r}
if (!requireNamespace("rpart", quietly = TRUE)) install.packages("rpart")
library(rpart)


df = read_excel("C:\\Users\\zrsm9\\OneDrive\\Documents\\CSC587\\HW3.3 Table.xlsx")
expanded <- df[rep(seq_len(nrow(df)), df$count), c("department","age","salary","status")]
expanded$department <- factor(expanded$department)
expanded$age        <- factor(expanded$age)
expanded$salary     <- factor(expanded$salary)
expanded$status     <- factor(expanded$status, levels = c("junior","senior"))

tree = rpart::rpart(status ~ department + age + salary,
                     data = expanded,
                     method = "class",
                     control = rpart.control(cp = 0.001, minsplit = 1))

print(tree)
cat("\nDetailed tree (rpart text):\n")
summary(tree)

extract_rules_safe <- function(rpart_model, data, target) {
  # rpart_model: fitted rpart object
  # data: the data used to fit the model (one-row-per-instance)
  # target: character name of the class column in data
  if (is.null(rpart_model$frame)) stop("Provide a valid rpart model")
  fr <- rpart_model$frame
  leaves <- as.numeric(rownames(fr[fr$var == "<leaf>", ]))
  # map observations to terminal node numbers
  obs_nodes <- rpart_model$where
  # ensure target is factor
  data[[target]] <- as.factor(data[[target]])
  class_levels <- levels(data[[target]])
  rules <- vector("character", length(leaves))
  i <- 1
  for (node in leaves) {
    # build condition string
    p <- path.rpart(rpart_model, nodes = node, print.it = FALSE)[[1]]
    conds <- p[-1]
    conds <- trimws(conds)
    cond_str <- if (length(conds) == 0) "TRUE" else paste(conds, collapse = " AND ")
    # find observations that fall in this leaf
    obs_idx <- which(obs_nodes == node)
    support <- length(obs_idx)
    if (support == 0) {
      probs <- rep(0, length(class_levels))
      names(probs) <- class_levels
    } else {
      tab <- table(data[[target]][obs_idx])
      probs <- as.numeric(tab / sum(tab))
      # align with full levels
      probs_full <- setNames(rep(0, length(class_levels)), class_levels)
      probs_full[names(tab)] <- as.numeric(tab) / sum(tab)
      probs <- probs_full
    }
    # predicted class (highest prob; ties -> first)
    pred_class <- names(which.max(probs))
    probs_str <- paste0(class_levels, "=", round(probs, 3), collapse = ", ")
    rules[i] <- sprintf("IF %s THEN %s = %s  [support=%d, probs: %s]",
                        cond_str, target, pred_class, support, probs_str)
    i <- i + 1
  }
  rules
}
```
